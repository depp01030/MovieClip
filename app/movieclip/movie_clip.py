import os
import aiohttp
import asyncio
from playwright.async_api import async_playwright
#from app.movieclip.config import ENTRANCEPOINT_URL

SEARCH_TERM = "i am surprised"
SEARCH_URL = "https://clip.cafe/?s={0}&usersearch=1&ss=s"
# SEARCH_URL = "https://yarn.co/yarn-find?text=i%20am%20surprised"
import os

async def download_video(url, save_path):
    # ğŸ§± ç¢ºä¿è³‡æ–™å¤¾å­˜åœ¨
    folder = os.path.dirname(save_path)
    os.makedirs(folder, exist_ok=True)

    async with aiohttp.ClientSession() as session:
        async with session.get(url) as resp:
            with open(save_path, "wb") as f:
                while True:
                    chunk = await resp.content.read(1024*1024)
                    if not chunk:
                        break
                    f.write(chunk)

    print(f"âœ… ä¸‹è¼‰å®Œæˆï¼š{save_path}")

 

async def scrape_videos(search_term):
    print("ğŸ¬ [movieclip] ä»»å‹™é–‹å§‹")
    search_url = SEARCH_URL.format(search_term.replace(" ","+")) 
    print(f"ğŸ” æœå°‹ç¶²å€ï¼š{search_url}")
    user_data_dir = "/tmp/playwright-chrome-profile"
    async with async_playwright() as p:
        context = await p.chromium.launch_persistent_context(
            user_data_dir,
            headless=False,
            executable_path="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome",
            args=[],
            viewport={"width": 1280, "height": 800},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/124.0.0.0 Safari/537.36"
        )
        page = context.pages[0] if context.pages else await context.new_page()
        await page.goto(search_url)
        # æ¨¡æ“¬çœŸäººæ»‘é¼ ç§»å‹•
        await page.mouse.move(100, 100)
        await page.wait_for_timeout(500)
        await page.mouse.move(200, 200)
        await page.wait_for_timeout(500)
        # await page.fill('#search-input', serching_term)
 
        # await page.click('#searchbox-frontpage > button')
        
        await page.wait_for_selector("#main-cont > div.searchResults > div")

        # å–å¾—æ‰€æœ‰æœå°‹çµæœå¡ç‰‡
        cards = await page.locator("#main-cont > div.searchResults > div").all()
        print(f"ğŸ” æ‰¾åˆ° {len(cards)} å€‹å½±ç‰‡å¡ç‰‡")

        # ç”¨ä¾†å­˜æŠ“åˆ°çš„ mp4 é€£çµï¼Œé¿å…é‡è¤‡ä¸‹è¼‰
        found_videos = set()

        # ç›£è½æ‰€æœ‰è«‹æ±‚
        async def on_request(request):
            url = request.url
            if 'blank' not in url and url.endswith(".mp4") and url not in found_videos:
                found_videos.add(url)
                print(f"ğŸ¯ åµæ¸¬åˆ°å½±ç‰‡è«‹æ±‚ï¼š{url}")
                # è‡ªå‹•ä¸‹è¼‰
                index = len(found_videos)
                save_path = f"downloads/{search_term}/{index}.mp4"
                await download_video(url, save_path)

        page.on("request", on_request)

        # hover æ‰€æœ‰é è¦½åœ–ä¾†è§¸ç™¼å½±ç‰‡è«‹æ±‚
        for i, card in enumerate(cards[:3]):
            print(f"\nğŸ–±ï¸ Hover ç¬¬ {i+1} å¼µå¡ç‰‡")
            hover_target = card.locator("div.searchResultClipImg")
            await hover_target.hover()
            await page.wait_for_timeout(3000)  # ç­‰ 3 ç§’
 

 
        await context.close()
        print("ğŸ æ‰€æœ‰ä»»å‹™å®Œæˆ")

